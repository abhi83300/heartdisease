load("C:/Users/abhi0/Downloads/heart_cleveland_upload.csv")
load("~/Heart_disease/Heart_disease.Rproj")
heart_cleveland_upload <- read.csv("C:/Users/abhi0/Downloads/heart_cleveland_upload.csv")
View(heart_cleveland_upload)
library(dplyr)
library(caret)
library(rpart)
library(stats)
View(heart_cleveland_upload)
# Read the data (assuming you have a CSV file)
data <- read.csv("heart_cleveland_upload.csv")
# Read the data (assuming you have a CSV file)
data <- read.csv("C:/Users/abhi0/Downloads/heart_cleveland_upload.csv")
# Rename columns
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "condition")
# Convert 'condition' to factor
data$condition <- as.factor(data$condition)
# Handle missing values (if any)
data <- na.omit(data)
# Feature scaling function
scale_features <- function(x) {
return((x - mean(x)) / sd(x))
}
# Apply scaling to all numeric columns
numeric_cols <- sapply(data, is.numeric)
data[numeric_cols] <- lapply(data[numeric_cols], scale_features)
# Split the data into training and testing sets
set.seed(123)
train_index <- sample(seq_len(nrow(data)), size = sample_size)
train_data <- data[train_index, ]
sample_size <- floor(0.8 * nrow(data))
train_index <- sample(seq_len(nrow(data)), size = sample_size)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Train linear regression model
lm_model <- glm(condition ~ ., data = train_data, family = "binomial")
# Train decision tree model
dt_model <- rpart(condition ~ ., data = train_data, method = "class")
# Create ensemble predictions
ensemble_predict <- function(newdata) {
lm_pred <- predict(lm_model, newdata, type = "response")
dt_pred <- predict(dt_model, newdata, type = "prob")[, 2]
# Combine predictions (simple average)
ensemble_pred <- (lm_pred + dt_pred) / 2
return(ensemble_pred)
}
# Make predictions on test data
test_predictions <- ensemble_predict(test_data)
# Convert predictions to binary (0 or 1) using a threshold of 0.5
test_predictions_binary <- ifelse(test_predictions > 0.5, 1, 0)
# Calculate accuracy
accuracy <- mean(as.numeric(test_predictions_binary) == as.numeric(test_data$condition) - 1)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# Function to predict for new data
predict_heart_disease_risk <- function(new_data) {
# Ensure new_data has the same structure as the training data
new_data <- as.data.frame(new_data)
colnames(new_data) <- colnames(data)[-14]  # Exclude 'condition' column
# Scale the new data
new_data[numeric_cols[-14]] <- lapply(new_data[numeric_cols[-14]], scale_features)
# Make prediction
risk_percentage <- ensemble_predict(new_data) * 100
return(risk_percentage)
}
# Example usage:
new_patient <- data.frame(
age = 55,
sex = 1,  # Assuming 1 for male, 0 for female
cp = 1,
trestbps = 140,
chol = 240,
fbs = 0,
restecg = 1,
thalach = 150,
exang = 0,
oldpeak = 1.5,
slope = 2,
ca = 0,
thal = 3
)
risk_percentage <- predict_heart_disease_risk(new_patient)
print(paste("Chance of critical heart condition:", round(risk_percentage, 2), "%"))
View(train_data)
View(new_patient)
View(heart_cleveland_upload)
View(data)
library(ROSE)
install.packages("ROSE")
library(ROSE)
library(ROSE)
# Read the data (assuming you have a CSV file)
data <- read.csv("C:/Users/abhi0/Downloads/heart_cleveland_upload.csv")
# Rename columns
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "condition")
# Convert 'condition' to factor
data$condition <- as.factor(data$condition)
data <- na.omit(data)
# Feature scaling function
scale_features <- function(x) {
return((x - mean(x)) / sd(x))
}
# Apply scaling to all numeric columns
numeric_cols <- sapply(data, is.numeric)
data[numeric_cols] <- lapply(data[numeric_cols], scale_features)
# Split the data into training and testing sets
set.seed(123)
sample_size <- floor(0.8 * nrow(data))
train_index <- sample(seq_len(nrow(data)), size = sample_size)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Train linear regression model
lm_model <- glm(condition ~ ., data = train_data, family = "binomial")
# Train decision tree model
dt_model <- rpart(condition ~ ., data = train_data, method = "class")
# Create ensemble predictions
ensemble_predict <- function(newdata) {
lm_pred <- predict(lm_model, newdata, type = "response")
dt_pred <- predict(dt_model, newdata, type = "prob")[, 2]
# Combine predictions (simple average)
ensemble_pred <- (lm_pred + dt_pred) / 2
return(ensemble_pred)
}
# Make predictions on test data
test_predictions <- ensemble_predict(test_data)
# Convert predictions to binary (0 or 1) using a threshold of 0.5
test_predictions_binary <- ifelse(test_predictions > 0.5, 1, 0)
# Calculate accuracy
accuracy <- mean(as.numeric(test_predictions_binary) == as.numeric(test_data$condition) - 1)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# Function to predict for new data
predict_heart_disease_risk <- function(new_data) {
# Ensure new_data has the same structure as the training data
new_data <- as.data.frame(new_data)
colnames(new_data) <- colnames(data)[-14]  # Exclude 'condition' column
# Scale the new data
new_data[numeric_cols[-14]] <- lapply(new_data[numeric_cols[-14]], scale_features)
# Make prediction
risk_percentage <- ensemble_predict(new_data) * 100
return(risk_percentage)
}
# Example usage:
new_patient <- data.frame(
age = 55,
sex = 1,  # Assuming 1 for male, 0 for female
cp = 1,
trestbps = 140,
chol = 240,
fbs = 0,
restecg = 1,
thalach = 150,
exang = 0,
oldpeak = 1.5,
slope = 2,
ca = 0,
thal = 3
)
risk_percentage <- predict_heart_disease_risk(new_patient)
print(paste("Chance of critical heart condition:", round(risk_percentage, 2), "%"))
View(data)
View(dt_model)
View(lm_model)
View(new_patient)
View(test_data)
View(ensemble_predict)
function(newdata) {
lm_pred <- predict(lm_model, newdata, type = "response")
dt_pred <- predict(dt_model, newdata, type = "prob")[, 2]
# Combine predictions (simple average)
ensemble_pred <- (lm_pred + dt_pred) / 2
return(ensemble_pred)
}
View(data)
# Load required libraries
library(rpart)
library(stats)
library(ROSE)
# Read the data (assuming you have a CSV file)
data <- read.csv("heart_disease_data.csv")
# Rename columns
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "condition")
# Read the data (assuming you have a CSV file)
data <- read.csv("C:/Users/abhi0/Downloads/heart_cleveland_upload.csv")
# Rename columns
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "condition")
# Convert 'condition' to factor
data$condition <- as.factor(data$condition)
# Handle missing values (if any)
data <- na.omit(data)
# Feature scaling function
scale_features <- function(x) {
return((x - mean(x)) / sd(x))
}
# Apply scaling to all numeric columns
numeric_cols <- sapply(data, is.numeric)
data[numeric_cols] <- lapply(data[numeric_cols], scale_features)
# Check original class distribution
print("Original class distribution:")
print(table(data$condition))
# Perform oversampling to balance the dataset
balanced_data <- ovun.sample(condition ~ ., data = data, method = "over", N = 2 * sum(data$condition == levels(data$condition)[1]))$data
# Check new class distribution
print("Balanced class distribution:")
print(table(balanced_data$condition))
# Train models on the balanced dataset
logistic_model <- glm(condition ~ ., data = balanced_data, family = binomial())
dt_model <- rpart(condition ~ ., data = balanced_data, method = "class")
# Create ensemble predictions
ensemble_predict <- function(newdata) {
logistic_pred <- predict(logistic_model, newdata, type = "response")
dt_pred <- predict(dt_model, newdata, type = "prob")[, 2]
# Combine predictions (simple average)
ensemble_pred <- (logistic_pred + dt_pred) / 2
return(ensemble_pred)
}
# Function to predict for all data
predict_heart_disease_risk <- function(data) {
# Make prediction
risk_percentage <- ensemble_predict(data[, -14]) * 100  # Exclude 'condition' column
return(risk_percentage)
}
# Calculate risk percentages for all people in the original dataset
risk_percentages <- predict_heart_disease_risk(data)
# Create a data frame with person ID and risk percentages
risk_df <- data.frame(
Person_ID = 1:nrow(data),
Risk_Percentage = round(risk_percentages, 2)
)
# Display the first few rows of the risk data frame
print("First few rows of risk percentages:")
print(head(risk_df))
# If you want to save this to a CSV file:
write.csv(risk_df, "heart_disease_risk_percentages.csv", row.names = FALSE)
print("Risk percentages have been calculated for all individuals and saved to 'heart_disease_risk_percentages.csv'")
View(predict_heart_disease_risk)
function(data) {
# Make prediction
risk_percentage <- ensemble_predict(data[, -14]) * 100  # Exclude 'condition' column
return(risk_percentage)
}
View(heart_cleveland_upload)
View(logistic_model)
View(risk_percentage)
view(risk_df)
view(risk_df)
View(risk_df)
install.packages("shiny")
library(shiny)
library(shiny)
# Define UI
ui <- fluidPage(
titlePanel("My Shiny App"),
sidebarLayout(
sidebarPanel(
textInput("name", "Enter your name:", ""),
numericInput("age", "Enter your age:", 0, min = 0, max = 120)
),
mainPanel(
textOutput("greeting")
)
)
)
# Define server logic
server <- function(input, output) {
output$greeting <- renderText({
paste("Hello,", input$name, "! You are", input$age, "years old.")
})
}
# Run the application
shinyApp(ui = ui, server = server)
library(shiny)
library(rpart)
library(stats)
library(ROSE)
# Load your data and prepare your models here
# (This part should be outside the UI and server functions)
data <- read.csv("C:/Users/abhi0/Downloads/heart_cleveland_upload.csv")
colnames(data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "condition")
data$condition <- as.factor(data$condition)
data <- na.omit(data)
scale_features <- function(x) {
return((x - mean(x)) / sd(x))
}
numeric_cols <- sapply(data, is.numeric)
data[numeric_cols] <- lapply(data[numeric_cols], scale_features)
balanced_data <- ovun.sample(condition ~ ., data = data, method = "over", N = 2 * sum(data$condition == levels(data$condition)[1]))$data
logistic_model <- glm(condition ~ ., data = balanced_data, family = binomial())
dt_model <- rpart(condition ~ ., data = balanced_data, method = "class")
ensemble_predict <- function(newdata) {
logistic_pred <- predict(logistic_model, newdata, type = "response")
dt_pred <- predict(dt_model, newdata, type = "prob")[, 2]
ensemble_pred <- (logistic_pred + dt_pred) / 2
return(ensemble_pred)
}
# Define UI
ui <- fluidPage(
titlePanel("Heart Disease Risk Prediction"),
sidebarLayout(
sidebarPanel(
numericInput("age", "Age", 50, min = 0, max = 120),
selectInput("sex", "Sex", choices = c("Male" = 1, "Female" = 0)),
selectInput("cp", "Chest Pain Type", choices = c("Typical Angina" = 0, "Atypical Angina" = 1, "Non-anginal Pain" = 2, "Asymptomatic" = 3)),
numericInput("trestbps", "Resting Blood Pressure", 120, min = 0),
numericInput("chol", "Cholesterol", 200, min = 0),
selectInput("fbs", "Fasting Blood Sugar > 120 mg/dl", choices = c("False" = 0, "True" = 1)),
selectInput("restecg", "Resting ECG Results", choices = c("Normal" = 0, "ST-T Wave Abnormality" = 1, "Left Ventricular Hypertrophy" = 2)),
numericInput("thalach", "Maximum Heart Rate Achieved", 150, min = 0),
selectInput("exang", "Exercise Induced Angina", choices = c("No" = 0, "Yes" = 1)),
numericInput("oldpeak", "ST Depression", 0, min = 0, step = 0.1),
selectInput("slope", "Slope of Peak Exercise ST Segment", choices = c("Upsloping" = 0, "Flat" = 1, "Downsloping" = 2)),
numericInput("ca", "Number of Major Vessels Colored by Flourosopy", 0, min = 0, max = 3),
selectInput("thal", "Thalassemia", choices = c("Normal" = 1, "Fixed Defect" = 2, "Reversable Defect" = 3))
),
mainPanel(
h3("Predicted Heart Disease Risk:"),
textOutput("risk")
)
)
)
# Define server logic
server <- function(input, output) {
output$risk <- renderText({
# Create a data frame from inputs
new_data <- data.frame(
age = as.numeric(input$age),
sex = as.numeric(input$sex),
cp = as.numeric(input$cp),
trestbps = as.numeric(input$trestbps),
chol = as.numeric(input$chol),
fbs = as.numeric(input$fbs),
restecg = as.numeric(input$restecg),
thalach = as.numeric(input$thalach),
exang = as.numeric(input$exang),
oldpeak = as.numeric(input$oldpeak),
slope = as.numeric(input$slope),
ca = as.numeric(input$ca),
thal = as.numeric(input$thal)
)
# Scale the new data
new_data <- as.data.frame(lapply(new_data, scale_features))
# Make prediction
risk <- ensemble_predict(new_data) * 100
paste(round(risk, 2), "%")
})
}
# Run the application
shinyApp(ui = ui, server = server)
runApp('C:/Users/abhi0/OneDrive/Desktop/Data Science/R')
